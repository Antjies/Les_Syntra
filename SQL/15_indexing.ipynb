{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Indexing\n",
    "\n",
    " the rate of data generation has grown substantially\n",
    "\n",
    " performance tuning. \n",
    "\n",
    " One of the most common performance optimization techniques\n",
    "is indexing. \n",
    "An index allows the SQL engine to quickly look up specific\n",
    "records in a table. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating an Index\n",
    "\n",
    "```\n",
    "CREATE INDEX <index name> ON <table name> (<column list>);\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We make a reasonable assumption that there are going to be\n",
    "a lot of queries using the language field in the WHERE clause, and creating\n",
    "an index on it would increase performance.\n",
    "\n",
    "```\n",
    "\n",
    "tesdb=# CREATE INDEX language_idx \n",
    "        ON proglang_tbl(language);\n",
    "        \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Let’s verify our index creation attempt by listing\n",
    "the table description \n",
    "\n",
    "in visual studio code => Open terminal => psql \n",
    "```\n",
    "tesdb=# \\d proglang_tbl;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using EXPLAIN to See Indexes at Work\n",
    "\n",
    " first let’s\n",
    "go about creating a large table to run our index-enabled queries on.\n",
    "\n",
    "A quick and dirty way to get a large table would be to use a cartesian\n",
    "product or cross joins. We already have our proglang_tbl with 5 columns\n",
    "and 9 rows in it. Doing a cartesian product on each of the fields with each\n",
    "other should yield us 9 to the power 5 = 59049 rows \n",
    "\n",
    "```\n",
    "tesdb=# SELECT a.language,\n",
    "                b.author,\n",
    "                c.year,\n",
    "                d.standard,\n",
    "                e.id\n",
    "        INTO biglang_tbl\n",
    "        FROM proglang_tbl a, proglang_tbl b, proglang_tbl c, proglang_tbl d, proglang_tbl e;\n",
    "\n",
    "tesdb=# SELECT count(*) FROM biglang_tbl;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to analyze the query\n",
    "time for finding all Fortran rows using EXPLAIN \n",
    "\n",
    "```\n",
    "tesdb=# EXPLAIN \n",
    "        SELECT * FROM biglang_tbl \n",
    "        WHERE language=\"Fortran\";\n",
    "```\n",
    "\n",
    "mentioned a Seq Scan or a sequential scan\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "after\n",
    "creating an index on the language field\n",
    "\n",
    "```\n",
    "tesdb=# CREATE INDEX biglang_idx \n",
    "        ON biglang_tbl (language);\n",
    "\n",
    "tesdb=# EXPLAIN \n",
    "        SELECT * FROM biglang_tbl \n",
    "        WHERE language='Fortran';\n",
    "```\n",
    "\n",
    "The current\n",
    "output mentions Bitmap Heap Scan and Bitmap Index Scan,\n",
    "\n",
    "Both plans mention a parameter-like cost=<1st value>..<2nd\n",
    "value>. The second value is the estimated total cost of query execution.\n",
    "The smaller this value is, the greater is the efficiency of query execution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unique Indexes\n",
    "\n",
    "can optionally specify the keyword UNIQUE during index creation \n",
    "\n",
    "```\n",
    "CREATE UNIQUE INDEX <index name> ON <table name> (<column\n",
    "list>)\n",
    "\n",
    "\n",
    "tesdb=# CREATE UNIQUE INDEX id_idx ON biglang_tbl (id);\n",
    "\n",
    "```\n",
    "\n",
    "ID field is actually duplicated many\n",
    "times due to our cross join conditions. Creating a unique index on this\n",
    "field would result in an error\n",
    "\n",
    "Checking a table with `\\d <table_name>` will show that primary key + unique are also indexes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How Do Indexes Work?\n",
    "\n",
    " it is helpful to think\n",
    "of it as an ordered lookup table. \n",
    "\n",
    "The values of the field being indexed are\n",
    "sorted and stored along with the pointers to the locations of the actual\n",
    "record in the base table\n",
    "\n",
    "The\n",
    "SQL interpreter would not have to traverse through the whole of the\n",
    "table to find the two rows with ANSI as the standard field. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/working_of_index.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When someone writes a query with a WHERE clause finding the specific\n",
    "value of a standard, this index would come into effect automatically\n",
    "without the user having to specify using it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Index Overheads\n",
    "\n",
    "like with everything else in the world, there is no\n",
    "free lunch.\n",
    "\n",
    "with N fields,\n",
    "then for every DML statement like INSERT, UPDATE, or DELETE, the N\n",
    "indexes have to be kept in sync. This makes changing data slow for large\n",
    "tables, sometimes annoyingly and sometimes worryingly\n",
    "\n",
    "\n",
    "Another serious overhead that too many indexes bring is their storage\n",
    "requirements. Indexes occupy physical space on the disk just like a table.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "```\n",
    "tesdb=# SELECT pg_size_pretty(pg_total_relation_size('biglang_tbl'))\n",
    "\n",
    "tesdb=# SELECT pg_size_pretty(pg_relation_size('biglang_idx'));\n",
    "```\n",
    "\n",
    "Our index is roughly 11% of the size of our table! \n",
    "\n",
    "A good rule of thumb is to rely on the primary key and unique indexes\n",
    "a lot during your queries. \n",
    "\n",
    "Over time you will start seeing patterns of slowrunning queries. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deleting an Index\n",
    "\n",
    "```\n",
    "DROP INDEX <index name>\n",
    "\n",
    "\n",
    "tesdb=# DROP INDEX biglang_idx;\n",
    "\n",
    "SELECT COUNT(*) FROM biglang_tbl;\n",
    "```\n",
    "\n",
    "DROP INDEX doesn’t change the contents of the\n",
    "underlying table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "```\n",
    "tesdb=# \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "```\n",
    "tesdb=# \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "```\n",
    "tesdb=# \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "```\n",
    "tesdb=# \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "```\n",
    "tesdb=# \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "```\n",
    "tesdb=# \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "```\n",
    "tesdb=# \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "```\n",
    "tesdb=# \n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "18a3ec44ede697772e2b2a8581e0f3291c9c47259057709d2626f9f8cd2d1d48"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
